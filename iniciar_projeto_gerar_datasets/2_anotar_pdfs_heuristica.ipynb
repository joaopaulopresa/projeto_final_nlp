{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(path):\n",
    "    with open(path, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        return json_object\n",
    "    \n",
    "def wirte_json_file(jsd,path):\n",
    "    class NpEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            if isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            if isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "    js = json.dumps(jsd, cls=NpEncoder,indent=4, ensure_ascii=False).encode('utf8')\n",
    "    with open(path, \"w\") as outfile:\n",
    "        outfile.write(js.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        words_pdf = pdf.pages[0].dedupe_chars(tolerance=1).extract_words()\n",
    "        words = []\n",
    "        for w in words_pdf:\n",
    "            x0,x1,y0,y1,text = round(w['x0']),round(w['x1']),round(w['top']),round(w['bottom']),w['text']\n",
    "            words.append({'box':[x0,y0,x1,y1],'text':text})\n",
    "        return words\n",
    "            \n",
    "    \n",
    "\n",
    "def get_max_rect(objects):\n",
    "    x0s,y0s,x1s,y1s = [],[],[],[]\n",
    "    for obj in objects:\n",
    "        x0,y0,x1,y1 = obj['box']\n",
    "        x0s.append(x0),y0s.append(y0),x1s.append(x1),y1s.append(y1)\n",
    "    max_rect = [min(x0s),min(y0s),max(x1s),max(y1s)]\n",
    "    return max_rect\n",
    "\n",
    "def is_date(text):\n",
    "    return re.match(r\"\\d+\\/\\d+\\/\\d+\",text) is not None\n",
    "\n",
    "def get_segment(id, label, words):\n",
    "    rect = get_max_rect(words)\n",
    "    txt = \" \".join([w['text'] for w in words])\n",
    "    segment = {'id':id,\n",
    "                'box':rect,\n",
    "                'label':label,\n",
    "                'text': txt,\n",
    "                'words': words}\n",
    "    return segment\n",
    "\n",
    "def get_header(words):\n",
    "    w_header = []\n",
    "    for w in words:\n",
    "        if not (is_date(w['text']) and w['box'][0] < 130):\n",
    "            w_header.append(w)\n",
    "        else:\n",
    "            break\n",
    "    w_header = [w for w in w_header if w['box'][0] > 40 ]\n",
    "    header = get_segment(0,'header',w_header)\n",
    "    return header \n",
    "\n",
    "def get_colegiado(words):\n",
    "    coleg_words = []\n",
    "    lasty0 = words[0]['box'][1]\n",
    "    for w in words:\n",
    "        dif = w['box'][1] - lasty0 \n",
    "        if dif < 5:\n",
    "            coleg_words.append(w)\n",
    "        else:\n",
    "            break\n",
    "        lasty0 = w['box'][1]    \n",
    "    colegseg = get_segment(2,'other',coleg_words)\n",
    "    return colegseg\n",
    "  \n",
    "def get_title(words):\n",
    "    title_words = []\n",
    "    lasty0 = words[0]['box'][1]\n",
    "    for w in words:\n",
    "        dif = w['box'][1] - lasty0 \n",
    "        if dif < 20:\n",
    "            title_words.append(w)\n",
    "        else:\n",
    "            break\n",
    "        lasty0 = w['box'][1]    \n",
    "    titleseg = get_segment(3,'title',title_words)\n",
    "    return titleseg\n",
    "\n",
    "def get_parte(words):\n",
    "    parte_words = []\n",
    "    lasty0 = words[0]['box'][1]\n",
    "    for w in words:\n",
    "        dif = w['box'][1] - lasty0 \n",
    "        if dif < 20:\n",
    "            parte_words.append(w)\n",
    "        else:\n",
    "            break\n",
    "        lasty0 = w['box'][1]    \n",
    "    parteseg = get_segment(4,'partes',parte_words)\n",
    "    return parteseg\n",
    "\n",
    "def check_acordao(w1,w2,w3):\n",
    "    if 'ACORDAO' in w1 or 'ACÓRDAO' in w1 or 'ACÓRDÃO' in w1 or 'ACORDÃO' in w1 or (('A' in w1 and len(w1) == 1) and ('C' in w2 and len(w2) == 1) and (('Ó' in w3 and len(w3) == 1) or ('O' in w3 and len(w3) == 1))):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_ementa_segs(words):\n",
    "    esegs = []\n",
    "    idx = 5\n",
    "    if ('EMENTA' in words[0]['text'] or 'Ementa' in words[0]['text'] ) and words[0]['box'][0] > 250:\n",
    "        heading_seg = get_segment(idx,'heading',[words[0]])\n",
    "        words = words[1:]\n",
    "        esegs.append(heading_seg)\n",
    "        idx+=1\n",
    "    ementa_words = []\n",
    "    for i in range(len(words)):\n",
    "        w1,w2,w3 = words[i],words[i + 1],words[i+2]\n",
    "        if check_acordao(w1['text'],w2['text'],w3['text']):\n",
    "            break\n",
    "        ementa_words.append(w1)\n",
    "    if len(ementa_words) > 0:   \n",
    "        ementaseg = get_segment(idx,'ementa',ementa_words)\n",
    "        esegs.append(ementaseg)\n",
    "    return esegs\n",
    "\n",
    "def get_acordao(idx,words):\n",
    "    awords = []\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if len(w['text']) == 1: \n",
    "            awords.append(w)\n",
    "            count+=1\n",
    "        else:\n",
    "            if (count > 6):\n",
    "                break\n",
    "            awords.append(w)\n",
    "            break\n",
    "    acaseg = get_segment(idx,'heading',awords)\n",
    "    return acaseg\n",
    "\n",
    "def get_acordao_txt(idx,words):\n",
    "    acordao_words = []\n",
    "    lasty0 = words[0]['box'][1]\n",
    "    for w in words:\n",
    "        dif = w['box'][1] - lasty0 \n",
    "        if dif < 27:\n",
    "            acordao_words.append(w)\n",
    "        else:\n",
    "            break\n",
    "        lasty0 = w['box'][1]    \n",
    "    acordaoseg = get_segment(idx,'acordao',acordao_words)\n",
    "    return acordaoseg\n",
    "\n",
    "def get_last_other_seqs(idx,words):\n",
    "    seqs = []\n",
    "    idxseq = idx\n",
    "    seq = []\n",
    "    lasty0 = words[0]['box'][1]\n",
    "    for w in words:\n",
    "        dif = w['box'][1] - lasty0 \n",
    "        if dif < 20:\n",
    "            seq.append(w)\n",
    "        else:\n",
    "            if len(seq) > 0:\n",
    "                titleseg = get_segment(idxseq,'other',seq)\n",
    "                seqs.append(titleseg)\n",
    "                idxseq+=1\n",
    "                seq = []\n",
    "                lasty0 = w['box'][1]\n",
    "                seq.append(w)\n",
    "        lasty0 = w['box'][1]\n",
    "    return seqs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_itd_m = open_json('ids_idt_mini.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for idx in ids_itd_m:\n",
    "    id = idx['id']\n",
    "   # try:\n",
    "    pdf_idtm_path = f'./ITD_MINI/{id}/{id}.pdf'\n",
    "    segs = []\n",
    "    new_doc = {\"id\":id}\n",
    "    words = get_words(pdf_idtm_path)\n",
    "    header = get_header(words)\n",
    "    header_y1 = header['box'][3]\n",
    "    words = [w for w in words if w['box'][1] > header_y1]\n",
    "    segs.append(header)\n",
    "    date = words[0]\n",
    "    dateseg = get_segment(1,'other',[date])\n",
    "    segs.append(dateseg)\n",
    "    words = words[1:]  \n",
    "    colegseg = get_colegiado(words)\n",
    "    segs.append(colegseg)\n",
    "    words = words[len(colegseg['words']):]\n",
    "    titleseg = get_title(words)\n",
    "    segs.append(titleseg)\n",
    "    words = words[len(titleseg['words']):]\n",
    "    parteseg = get_parte(words)\n",
    "    segs.append(parteseg)\n",
    "    words = words[len(parteseg['words']):]\n",
    "    ementa_segs = get_ementa_segs(words)\n",
    "    ementa_qtd = [len(e['words']) for e in ementa_segs]\n",
    "    ementa_qtd = sum(ementa_qtd)\n",
    "    last_id = ementa_segs[-1]['id']\n",
    "    segs+=ementa_segs\n",
    "    words = words[ementa_qtd:]\n",
    "    acordao_seq = get_acordao(last_id+1,words)\n",
    "    segs.append(acordao_seq)\n",
    "    last_id+=1\n",
    "    words = words[len(acordao_seq['words']):]\n",
    "    acordaotxt_seq = get_acordao_txt(last_id+1,words)\n",
    "    segs.append(acordaotxt_seq)\n",
    "    last_id+=1\n",
    "    words = words[len(acordaotxt_seq['words']):]\n",
    "    last_seqs = get_last_other_seqs(last_id+1,words)\n",
    "    if len(last_seqs) > 0:\n",
    "        segs+=last_seqs\n",
    "        last_seqs_qtd = [len(e['words']) for e in last_seqs]\n",
    "        last_seqs_qtd = sum(last_seqs_qtd)\n",
    "        last_id = last_seqs[-1]['id']\n",
    "        words = words[last_seqs_qtd:]\n",
    "    footerseg = get_segment(last_id+1,'footer',words)\n",
    "    segs.append(footerseg)\n",
    "    new_doc[\"documento\"] = segs\n",
    "    data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotacao_path = 'heuristica_anotacao.json'\n",
    "wirte_json_file(data,anotacao_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b32ddc4246e1f5eb2658859b04f31200bfc8399c2090cfc052083303736e7c59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
