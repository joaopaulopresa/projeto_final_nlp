{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import (\n",
    "    ClassificationModel, ClassificationArgs\n",
    ")\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(eval_df,model_outputs):\n",
    "    predictions = []\n",
    "    for x in model_outputs:\n",
    "        predictions.append(np.argmax(x))\n",
    "    f1 = f1_score(eval_df['labels'], predictions)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ementa</th>\n",
       "      <th>acordao</th>\n",
       "      <th>entail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEI – APLICAÇÃO NO TEMPO – TRIBUTO – IRRETROAT...</td>\n",
       "      <td>Vistos, relatados e discutidos estes autos, ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMUNIDADE – LIVROS FISCAIS. O fato de a pessoa...</td>\n",
       "      <td>Vistos, relatados e discutidos estes autos, ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEVIDO PROCESSO LEGAL – SITUAÇÃO CONSTITUÍDA –...</td>\n",
       "      <td>Vistos, relatados e discutidos estes autos, ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SERVIÇO PÚBLICO – DESLIGAMENTO – DEVIDO PROCES...</td>\n",
       "      <td>Vistos, relatados e discutidos estes autos, ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMENTA: RECURSO EXTRAORDINÁRIO. CONSTITUCIONAL...</td>\n",
       "      <td>Vistos, relatados e discutidos estes autos, ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ementa  \\\n",
       "0  LEI – APLICAÇÃO NO TEMPO – TRIBUTO – IRRETROAT...   \n",
       "1  IMUNIDADE – LIVROS FISCAIS. O fato de a pessoa...   \n",
       "2  DEVIDO PROCESSO LEGAL – SITUAÇÃO CONSTITUÍDA –...   \n",
       "3  SERVIÇO PÚBLICO – DESLIGAMENTO – DEVIDO PROCES...   \n",
       "4  EMENTA: RECURSO EXTRAORDINÁRIO. CONSTITUCIONAL...   \n",
       "\n",
       "                                             acordao  entail  \n",
       "0  Vistos, relatados e discutidos estes autos, ac...       1  \n",
       "1  Vistos, relatados e discutidos estes autos, ac...       1  \n",
       "2  Vistos, relatados e discutidos estes autos, ac...       1  \n",
       "3  Vistos, relatados e discutidos estes autos, ac...       1  \n",
       "4  Vistos, relatados e discutidos estes autos, ac...       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ementa_acordao_rte.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for ementa,acordao,label in df.values:\n",
    "  X.append([ementa,acordao,label])\n",
    "  y.append(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 858\n"
     ]
    }
   ],
   "source": [
    "print('total samples:',len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 686 test size: 172\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed)\n",
    "train_data = []\n",
    "eval_data = []\n",
    "for example in X_train:\n",
    "  train_data.append(example)\n",
    "for example in X_test:\n",
    "  eval_data.append(example)\n",
    "print('train size:',len(train_data),'test size:',len(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.columns = [\"text_a\", \"text_b\", \"labels\"]\n",
    "eval_df = pd.DataFrame(eval_data)\n",
    "eval_df.columns = [\"text_a\", \"text_b\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    102\n",
       "0     70\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['labels'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    408\n",
       "0    278\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['labels'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(output_d):\n",
    "    model_args = ClassificationArgs(num_train_epochs=2,use_multiprocessing = False,\n",
    "                                use_multiprocessing_for_evaluation = False,\n",
    "                                overwrite_output_dir = True,\n",
    "                                manual_seed=seed,\n",
    "                                output_dir=output_d,\n",
    "                                fp16=False)\n",
    "    return model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model_outputs/legal_bERTimbau_sts_large_output': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Legal-BERTimbau-sts-large-ma-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'model_outputs/legal_bERTimbau_sts_large_output'\n",
    "!rm -r $output_dir\n",
    "model_args = get_args(output_dir)\n",
    "name = 'Legal-BERTimbau-sts-large-ma-v3'\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"Legal-BERTimbau-sts-large-ma-v3\", args=model_args,use_cuda=True, ignore_mismatched_sizes=True\n",
    ")\n",
    "models.append((model,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model_outputs/legal_bERTimbau_large_output': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Legal-BERTimbau-large-TSDAE-v5 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'model_outputs/legal_bERTimbau_large_output'\n",
    "!rm -r $output_dir\n",
    "model_args = get_args(output_dir)\n",
    "name = 'Legal-BERTimbau-large-TSDAE-v5'\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"Legal-BERTimbau-large-TSDAE-v5\", args=model_args,use_cuda=True, ignore_mismatched_sizes=True\n",
    ")\n",
    "models.append((model,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model_outputs/legal_bERTimbau_base_output': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Legal-BERTimbau-base-TSDAE and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'model_outputs/legal_bERTimbau_base_output'\n",
    "!rm -r $output_dir\n",
    "model_args = get_args(output_dir)\n",
    "name = 'Legal-BERTimbau-base-TSDAE'\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"Legal-BERTimbau-base-TSDAE\", args=model_args,use_cuda=True, ignore_mismatched_sizes=True\n",
    ")\n",
    "models.append((model,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model_outputs/court_decisions_output': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'model_outputs/court_decisions_output'\n",
    "!rm -r $output_dir\n",
    "model_args = get_args(output_dir)\n",
    "name = 'bertimbau-base-finetuned-brazilian_court_decisions'\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"bertimbau-base-finetuned-brazilian_court_decisions\", args=model_args,use_cuda=True, ignore_mismatched_sizes=True\n",
    ")\n",
    "models.append((model,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model_outputs/base_portuguese_output': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'model_outputs/base_portuguese_output'\n",
    "!rm -r $output_dir\n",
    "model_args = get_args(output_dir)\n",
    "name = 'bert-base-portuguese-cased'\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"bert-base-portuguese-cased\", args=model_args,use_cuda=True, ignore_mismatched_sizes=True,\n",
    ")\n",
    "models.append((model,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'model_outputs/base_multilingual_output'\n",
    "!rm -r $output_dir\n",
    "model_args = get_args(output_dir)\n",
    "name = 'bert-base-multilingual-cased'\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"bert-base-multilingual-cased\", args=model_args,use_cuda=True, ignore_mismatched_sizes=True,\n",
    ")\n",
    "models.append((model,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model Legal-BERTimbau-sts-large-ma-v3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aa1e796e7c42ef90041981ea7a108e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82504328991d4f7f91b58f327df09939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa23bdf2b2145c290dbf391f7dcc782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to model_outputs/base_multilingual_output.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model Legal-BERTimbau-large-TSDAE-v5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e23e74fb0534105b826a471632d48ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8d871c703244cf92e73f7750666cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c4a592ad97427c9687248c88c4b655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to model_outputs/base_multilingual_output.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_2_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model Legal-BERTimbau-base-TSDAE:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaa262ac0d84273b72d7da3b5075a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee9cd61b8694974bba648a30bbb543b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a111f3c8523a404a84a4a0e7ca30c00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to model_outputs/base_multilingual_output.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_2_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model bertimbau-base-finetuned-brazilian_court_decisions:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f04a089c404da5a9843e60c4230711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fcfe5ee8c0443f9fa6d4b15113691b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e85df545ebf4786a8779cdb4862515d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to model_outputs/base_multilingual_output.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_2_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model bert-base-portuguese-cased:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77cf65b97d845e28e5eb02528b09f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd9a3e49e6a422bbd8fa67f2b722973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2a4d70203e4d4489de9146d6544e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to model_outputs/base_multilingual_output.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_2_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model bert-base-multilingual-cased:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee26d6ec451474c804232b841be09bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df63884cd33f4c38b9c8e7c300cf5877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de1e449c3a74a6bb498672d7c7fb537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to model_outputs/base_multilingual_output.\n"
     ]
    }
   ],
   "source": [
    "trained_models = []\n",
    "for model, name in models:\n",
    "    print(f'training model {name}:')\n",
    "    model.train_model(train_df)\n",
    "    trained_models.append((model,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ab7e1ebc904e518775bade83adec80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.40187543791837627, 'tp': 81, 'tn': 42, 'fp': 28, 'fn': 21, 'auroc': 0.8004201680672268, 'auprc': 0.8610616607656268, 'eval_loss': 0.6266042390330271}\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43c7b6a81a04018a2193983def6189e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.379666860786319, 'tp': 74, 'tn': 46, 'fp': 24, 'fn': 28, 'auroc': 0.7438375350140056, 'auprc': 0.8080016654977341, 'eval_loss': 0.5994966077533636}\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c9ddaa54e34ea997e976e17edee499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7699847368322048, 'tp': 95, 'tn': 58, 'fp': 12, 'fn': 7, 'auroc': 0.9301120448179272, 'auprc': 0.9220956915790613, 'eval_loss': 0.32674143548038875}\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3131ee1bb68a406eaeca0aaf3944d0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.6844205247457985, 'eval_loss': 0.38027972457083786}\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd551d7c99140f8a6f80e2be44d5df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8722437173187451, 'tp': 102, 'tn': 59, 'fp': 11, 'fn': 0, 'auroc': 0.9565826330532212, 'auprc': 0.9592621015204901, 'eval_loss': 0.22064606938511133}\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c1c1b0b2904ac68b3ca2a393dd15bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.4860940847675411, 'tp': 91, 'tn': 39, 'fp': 31, 'fn': 11, 'auroc': 0.780672268907563, 'auprc': 0.8283721524280665, 'eval_loss': 0.5758592323823408}\n"
     ]
    }
   ],
   "source": [
    "model_results = []\n",
    "for model,name in trained_models:\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(\n",
    "    eval_df\n",
    ")\n",
    "    f1 = get_f1_score(eval_df,model_outputs)\n",
    "    result['f1-score'] = f1\n",
    "    model_results.append((result,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Legal-BERTimbau-sts-large-ma-v3\n",
      "Resultados: \n",
      "{ 'auprc': 0.8610616607656268,\n",
      "  'auroc': 0.8004201680672268,\n",
      "  'eval_loss': 0.6266042390330271,\n",
      "  'f1-score': 0.7677725118483412,\n",
      "  'fn': 21,\n",
      "  'fp': 28,\n",
      "  'mcc': 0.40187543791837627,\n",
      "  'tn': 42,\n",
      "  'tp': 81}\n",
      "Modelo: Legal-BERTimbau-large-TSDAE-v5\n",
      "Resultados: \n",
      "{ 'auprc': 0.8080016654977341,\n",
      "  'auroc': 0.7438375350140056,\n",
      "  'eval_loss': 0.5994966077533636,\n",
      "  'f1-score': 0.74,\n",
      "  'fn': 28,\n",
      "  'fp': 24,\n",
      "  'mcc': 0.379666860786319,\n",
      "  'tn': 46,\n",
      "  'tp': 74}\n",
      "Modelo: Legal-BERTimbau-base-TSDAE\n",
      "Resultados: \n",
      "{ 'auprc': 0.9220956915790613,\n",
      "  'auroc': 0.9301120448179272,\n",
      "  'eval_loss': 0.32674143548038875,\n",
      "  'f1-score': 0.9090909090909091,\n",
      "  'fn': 7,\n",
      "  'fp': 12,\n",
      "  'mcc': 0.7699847368322048,\n",
      "  'tn': 58,\n",
      "  'tp': 95}\n",
      "Modelo: bertimbau-base-finetuned-brazilian_court_decisions\n",
      "Resultados: \n",
      "{ 'eval_loss': 0.38027972457083786,\n",
      "  'f1-score': 0.8773584905660377,\n",
      "  'mcc': 0.6844205247457985}\n",
      "Modelo: bert-base-portuguese-cased\n",
      "Resultados: \n",
      "{ 'auprc': 0.9592621015204901,\n",
      "  'auroc': 0.9565826330532212,\n",
      "  'eval_loss': 0.22064606938511133,\n",
      "  'f1-score': 0.9488372093023255,\n",
      "  'fn': 0,\n",
      "  'fp': 11,\n",
      "  'mcc': 0.8722437173187451,\n",
      "  'tn': 59,\n",
      "  'tp': 102}\n",
      "Modelo: bert-base-multilingual-cased\n",
      "Resultados: \n",
      "{ 'auprc': 0.8283721524280665,\n",
      "  'auroc': 0.780672268907563,\n",
      "  'eval_loss': 0.5758592323823408,\n",
      "  'f1-score': 0.8125000000000002,\n",
      "  'fn': 11,\n",
      "  'fp': 31,\n",
      "  'mcc': 0.4860940847675411,\n",
      "  'tn': 39,\n",
      "  'tp': 91}\n"
     ]
    }
   ],
   "source": [
    "for result,name in model_results:\n",
    "    r = pprint.pformat(result, indent=2)\n",
    "    print(f'Modelo: {name}\\nResultados: \\n{r}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
